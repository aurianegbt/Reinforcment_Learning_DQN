{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2eea6c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7be7ff",
   "metadata": {},
   "source": [
    "<font color=seagreen> \n",
    "    <u> Note sur le package </u> \n",
    "    \n",
    "L'implémentation ci-dessus est réalisé avec la librairie `keras` et plus particulièrement les fonctions suivantes : \n",
    "    - \n",
    "    -\n",
    "    -\n",
    "    -\n",
    "    -\n",
    "    -\n",
    "    -\n",
    "    -\n",
    "    -\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a9999c",
   "metadata": {},
   "source": [
    "# <u> 2. Réseau de Neuronnes </u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ecaba4",
   "metadata": {},
   "source": [
    "Dans le but d'implémenter l'algorithme DQN, il est nécessaire de mettre en place un réseau de neuronnes. Pour ça, on va créée un modèle représentant ce réseau. On définit la méthode d'initialisation de notre réseau via la conftion `__init__` comme vu précédemment. Celle-ci dépend de deux arguments : `iS` (_input shape_) et `learning_rate`. Nous initialisons ses valeurs par défault à $(100,100,3)$ et $0.0005$ d'après la littérature. Le noyau est ensuite initialisé d'après la méthode décrite dans~\\cite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "946566b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class neural_kernel():\n",
    "    def __init__(self,iS=(100,100,3),learning_rate=0.0005):\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "        self.input_shape = iS\n",
    "        self.n_outputs = 4    # UP, DOWN, LEFT, RIGHT\n",
    "        self.model = Sequential() #modèle vide\n",
    "\n",
    "        # Ajout de couche au modèle :\n",
    "        self.model.add(Conv2D(32, (3,3), activation ='relu', input_shape = self.input_shape))\n",
    "        self.model.add(MaxPooling2D((2,2)))\n",
    "        self.model.add(Conv2D(64, (2,2), activation = 'relu'))\n",
    "        self.model.add(Flatten())\n",
    "        self.model.add(Dense(units = 256, activation = 'relu'))\n",
    "        self.model.add(Dense(units = self.n_outputs))\n",
    "\n",
    "        # On fournit au modèle comment calculer l'erreur et quelle fonction pour l'optimiser\n",
    "        self.model.compile(loss = 'mean_squared_error', optimizer = Adam(learning_rate = self.learning_rate))\n",
    "\n",
    "    def loadModel(self, filepath):\n",
    "        self.model = load_model(filepath)\n",
    "        return self.model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
